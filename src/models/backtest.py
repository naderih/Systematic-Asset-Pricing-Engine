"""
Module: Backtest Engine

OBJECTIVE:
    Simulates the historical performance of the generated portfolio strategy.
    
    This module acts as the "Time Machine." It takes the Point-in-Time holdings 
    generated by the Portfolio Optimizer and replays history to calculate:
    1. Realized Returns (Total, Active, and Excess).
    2. Risk Metrics (Volatility, Tracking Error, Drawdown).
    3. Trading Costs (Turnover).

METHODOLOGY:
    1. Lag Enforcement:
       We strictly align Holdings(t) with Returns(t+1). You cannot earn returns 
       on a stock until *after* you have bought it.

    2. Risk-Free Rate Integration:
       Fetches Fama-French risk-free rates (RF) to calculate "True Sharpe Ratio."
       Sharpe = (Portfolio Return - Risk Free Rate) / Volatility

    3. Performance Attribution:
       Decomposes returns into Benchmark component and Active component.
       Active Return = Portfolio Return - Benchmark Return.
"""

import os
import pandas as pd
import numpy as np
import pandas_datareader.data as web
import warnings

class BacktestEngine:
    """
    Evaluates the historical performance of the optimal portfolio.
    
    Attributes:
        data_dir (str): Path to processed datasets.
        rf_rate (pd.DataFrame): Time series of risk-free rates (monthly).
        holdings (pd.DataFrame): The historical portfolio weights.
        returns (pd.DataFrame): The realized stock returns.
    """
    
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.rf_rate = None

    def load_data(self):
        """
        Loads optimal holdings, realized stock returns, and risk-free rate.
        Performs strict index alignment to ensure data integrity.
        """
        print("Loading Backtest Data...")
        
        # 1. Load Holdings (Generated by portfolio.py)
        holdings_path = os.path.join(self.data_dir, 'optimal_holdings.parquet')
        if not os.path.exists(holdings_path):
            raise FileNotFoundError("optimal_holdings.parquet not found. Run portfolio.py first.")
        
        self.holdings = pd.read_parquet(holdings_path)
        
        # 2. Load Realized Returns (Panel Data)
        panel_path = os.path.join(self.data_dir, 'panel_data.parquet')
        panel = pd.read_parquet(panel_path)
        
        # --- ID Preservation ---
        # Reset index immediately to ensure 'permno' and 'date' are accessible columns
        panel.reset_index(inplace=True)
        
        # Select only what we need for the backtest
        required_cols = ['permno', 'date', 'ret_monthly']
        
        # Validation check
        missing = [c for c in required_cols if c not in panel.columns]
        if missing:
            raise KeyError(f"Panel data missing columns: {missing}. Check merger.py output.")
            
        self.returns = panel[required_cols].copy()
        
        # 3. Clean up Types & Indexing
        self.holdings.reset_index(inplace=True)
        
        # Enforce datetime type for safe merging
        self.holdings['date'] = pd.to_datetime(self.holdings['date'])
        self.returns['date'] = pd.to_datetime(self.returns['date'])
        
        # Set MultiIndex [permno, date] for efficient joining
        self.holdings.set_index(['permno', 'date'], inplace=True)
        self.returns.set_index(['permno', 'date'], inplace=True)
        
        # Sort indices (Crucial for time-series operations)
        self.holdings.sort_index(inplace=True)
        self.returns.sort_index(inplace=True)
        
        print("Core data loaded.")
        
        # 4. Fetch Risk-Free Rate
        self._fetch_risk_free_rate()

    def _fetch_risk_free_rate(self):
        """
        Fetches Fama-French Risk-Free Rate (RF) to calculate Excess Returns.
        Handles API warnings and connection failures gracefully.
        """
        print("Fetching Fama-French Risk-Free Rate...")
        
        try:
            start_date = self.returns.index.get_level_values('date').min()
            end_date = self.returns.index.get_level_values('date').max()
            
            # --- SUPPRESS WARNINGS ---
            # pandas-datareader uses an old 'date_parser' argument deprecated in Pandas 2.0.
            # We silence this specific warning to keep the console clean.
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=FutureWarning)
                ff_data = web.DataReader('F-F_Research_Data_Factors', 'famafrench', start=start_date, end=end_date)[0]
            # -------------------------
            
            # Rename and format
            ff_data.rename(columns={'RF': 'rf'}, inplace=True)
            ff_data = ff_data[['rf']] / 100.0 # Convert from percent (0.4) to decimal (0.004)
            
            # Convert index to End-of-Month to match our panel frequency
            ff_data.index = ff_data.index.to_timestamp(freq='M')
            
            self.rf_rate = ff_data
            print("Risk-Free rate loaded successfully.")
            
        except Exception as e:
            print(f"Warning: Could not fetch Risk-Free rate ({e}). Defaulting RF to 0.0.")
            # Fallback: Create a Series of zeros matching the unique dates in our sample
            unique_dates = self.returns.index.get_level_values('date').unique()
            self.rf_rate = pd.DataFrame({'rf': 0.0}, index=unique_dates)

    def run_backtest(self, start_date=None):
        """
        Calculates the time-series of portfolio returns.
        
        Args:
            start_date (str): Optional. Start trading from this date (e.g., '1995-01-01').
                              Useful to skip the "burn-in" period where rolling factors (like Beta) are zero.
        """
        print("Running Backtest Simulation...")
        
        # --- Step 1: Lag Management ---
        # Align Holdings(T) with Returns(T+1)
        # We shift returns backwards by -1 (bringing future returns to the current row)
        # so that Row T contains: Holdings(T) and Returns(T+1).
        self.returns.sort_index(level=['permno', 'date'], inplace=True)
        self.returns['ret_future'] = self.returns.groupby('permno')['ret_monthly'].shift(-1)
        
        # Inner Join: We only keep rows where we have BOTH a position and a future return.
        df = self.holdings.join(self.returns[['ret_future']], how='inner')
        
        # --- Step 2: Apply Burn-In Period ---
        if start_date:
            print(f"Applying Burn-in: Starting backtest from {start_date}...")
            df = df[df.index.get_level_values('date') >= pd.to_datetime(start_date)]
        
        # --- Step 3: Calculate Portfolio Returns ---
        # Portfolio Return = Sum(Weight_i * Return_i)
        def calc_weighted_ret(group):
            port_ret = (group['h_portfolio'] * group['ret_future']).sum()
            bench_ret = (group['h_benchmark'] * group['ret_future']).sum()
            return pd.Series({'port_ret': port_ret, 'bench_ret': bench_ret})

        performance = df.groupby('date').apply(calc_weighted_ret)
        
        # --- Step 4: Integrate Risk-Free Rate ---
        # Join RF data to the calculated performance series
        performance = performance.join(self.rf_rate, how='left').fillna(0)
        
        # Calculate Derived Metrics
        performance['active_ret'] = performance['port_ret'] - performance['bench_ret']
        performance['excess_ret'] = performance['port_ret'] - performance['rf']
        
        # Calculate Cumulative Wealth (Log-like growth)
        performance['cum_port'] = (1 + performance['port_ret']).cumprod()
        performance['cum_bench'] = (1 + performance['bench_ret']).cumprod()
        performance['cum_active'] = (1 + performance['active_ret']).cumprod()
        
        self.performance = performance
        
        # --- Step 5: Calculate Turnover ---
        # Turnover = Sum(|Weight_t - Weight_t-1|) / 2
        # We must slice the original holdings to match the start_date logic
        if start_date:
            sliced_holdings = self.holdings[self.holdings.index.get_level_values('date') >= pd.to_datetime(start_date)]
            w_p = sliced_holdings['h_portfolio'].unstack(level='permno').fillna(0)
        else:
            w_p = self.holdings['h_portfolio'].unstack(level='permno').fillna(0)
            
        self.turnover = w_p.diff().abs().sum(axis=1) / 2
        
        return performance
 
    def generate_tearsheet(self):
        """
        Calculates and prints an institutional-grade performance report.
        """
        stats = self.performance
        ANN = 12 # Annualization Factor (Monthly Data)
        
        # 1. Total Return (Geometric Annualized)
        # Note: Arithmetic mean approximation is standard for simple tearsheets, 
        # but geometric is more precise for long periods. We stick to arithmetic for clarity here.
        total_ret_ann = stats['port_ret'].mean() * ANN
        bench_ret_ann = stats['bench_ret'].mean() * ANN
        
        # 2. Volatility (Annualized Std Dev)
        total_vol_ann = stats['port_ret'].std() * np.sqrt(ANN)
        active_vol_ann = stats['active_ret'].std() * np.sqrt(ANN) # Tracking Error
        
        # 3. Risk-Adjusted Ratios
        # Sharpe = Excess Return / Volatility of Excess Return
        excess_vol_ann = stats['excess_ret'].std() * np.sqrt(ANN)
        sharpe = (stats['excess_ret'].mean() * ANN) / excess_vol_ann
        
        # Information Ratio = Active Return / Tracking Error
        ir = (stats['active_ret'].mean() * ANN) / active_vol_ann
        
        # 4. Max Drawdown
        # Peak-to-Trough decline
        cum_ret = (1 + stats['port_ret']).cumprod()
        peak = cum_ret.cummax()
        drawdown = (cum_ret - peak) / peak
        max_dd = drawdown.min()
        
        # 5. Average Turnover
        avg_turnover = self.turnover.mean()
        
        # --- PRINT REPORT ---
        print("\n" + "="*40)
        print(f"{'BACKTEST PERFORMANCE REPORT':^40}")
        print("="*40)
        print(f"Annualized Return:     {total_ret_ann:.2%}")
        print(f"Benchmark Return:      {bench_ret_ann:.2%}")
        print(f"Active Return:         {total_ret_ann - bench_ret_ann:.2%}")
        print("-" * 40)
        print(f"Portfolio Volatility:  {total_vol_ann:.2%}")
        print(f"Tracking Error:        {active_vol_ann:.2%}")
        print("-" * 40)
        print(f"Sharpe Ratio (Rf adj): {sharpe:.2f}")
        print(f"Information Ratio:     {ir:.2f}")
        print("-" * 40)
        print(f"Max Drawdown:          {max_dd:.2%}")
        print(f"Avg Monthly Turnover:  {avg_turnover:.2%}")
        print("="*40)
        
        # Save summary metrics
        save_path = os.path.join(self.data_dir, 'backtest_metrics.csv')
        metrics = pd.Series({
            'Return': total_ret_ann,
            'Sharpe': sharpe,
            'IR': ir,
            'MaxDD': max_dd,
            'Turnover': avg_turnover
        })
        metrics.to_csv(save_path)
        
        # Save Full Equity Curve
        curve_path = os.path.join(self.data_dir, 'equity_curve.csv')
        self.performance.to_csv(curve_path)
        print(f"Results saved to {self.data_dir}")

if __name__ == "__main__":
    pass